{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a820e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ab3065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S No.</th>\n",
       "      <th>Title</th>\n",
       "      <th>Decisions</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SpiceJet to issue 6.4 crore warrants to promoters</td>\n",
       "      <td>{\"SpiceJet\": \"neutral\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MMTC Q2 net loss at Rs 10.4 crore</td>\n",
       "      <td>{\"MMTC\": \"neutral\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mid-cap funds can deliver more, stay put: Experts</td>\n",
       "      <td>{\"Mid-cap funds\": \"positive\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mid caps now turn into market darlings</td>\n",
       "      <td>{\"Mid caps\": \"positive\"}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S No.                                              Title  \\\n",
       "0      1  SpiceJet to issue 6.4 crore warrants to promoters   \n",
       "1      2                  MMTC Q2 net loss at Rs 10.4 crore   \n",
       "2      3  Mid-cap funds can deliver more, stay put: Experts   \n",
       "3      4             Mid caps now turn into market darlings   \n",
       "\n",
       "                       Decisions  Words  \n",
       "0        {\"SpiceJet\": \"neutral\"}      8  \n",
       "1            {\"MMTC\": \"neutral\"}      8  \n",
       "2  {\"Mid-cap funds\": \"positive\"}      8  \n",
       "3       {\"Mid caps\": \"positive\"}      7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral https://t....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  $BYND - JPMorgan reels in expectations on Beyo...      0\n",
       "1  $CCL $RCL - Nomura points to bookings weakness...      0\n",
       "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0\n",
       "3  $ESS: BTIG Research cuts to Neutral https://t....      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1 = pd.read_csv('Data/SEntFiN-v1.1.csv') # https://www.kaggle.com/datasets/ankurzing/aspect-based-sentiment-analysis-for-financial-news \",\n",
    "data2 = pd.read_csv('Data/sent_train.csv') # https://www.kaggle.com/datasets/borhanitrash/twitter-financial-news-sentiment-dataset\",\n",
    "data3 = pd.read_csv('Data/data.csv') # https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\",\n",
    "data4 = pd.read_csv('Data/all-data.csv', names=[\"sentiment\", \"text\"], encoding=\"utf-8\", encoding_errors=\"replace\") # https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-for-financial-news1\",\n",
    "display(data1.head(4))\n",
    "display(data2.head(4)) # In first rows it seemed like in each sentence contains the symbol, on further inspection it seems like the symbol is not always present.1\",\n",
    "display(data3.head(4))\n",
    "display(data4.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5fded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "COMMODITY = {\n",
    "    \"gold\", \"silver\", \"platinum\", \"palladium\", \"copper\", \"aluminum\", \"nickel\",\n",
    "    \"zinc\", \"lead\", \"tin\", \"iron ore\", \"steel\", \"cobalt\", \"uranium\", \"crude oil\",\n",
    "    \"oil\", \"brent\", \"wti\", \"gasoline\", \"diesel\", \"jet fuel\", \"natural gas\",\n",
    "    \"heating oil\", \"coal\", \"propane\", \"fuel oil\", \"wheat\", \"corn\", \"maize\",\n",
    "    \"soybeans\", \"rapeseed\", \"canola\", \"rice\", \"barley\", \"oats\", \"sorghum\",\n",
    "    \"coffee\", \"cocoa\", \"cotton\", \"sugar\", \"orange juice\", \"palm oil\", \"rubber\",\n",
    "    \"tea\", \"live cattle\", \"lean hogs\", \"milk\", \"lumber\"\n",
    "}\n",
    "\n",
    "GPE = {c.name.lower() for c in pycountry.countries}\n",
    "GPE.update({\"usa\", \"u.s.\", \"us\", \"u.k.\", \"uk\", \"europe\"})\n",
    "\n",
    "CURRENCY = {\n",
    "    \"dollar\", \"dollars\", \"euro\", \"euros\", \"yen\", \"yens\", \"yuan\", \"pound\",\n",
    "    \"pounds\", \"rupee\", \"rupees\", \"franc\", \"francs\"\n",
    "}\n",
    "\n",
    "CONCEPT = {\n",
    "    \"market\", \"markets\", \"stocks\", \"world stocks\", \"mid caps\", \"mid-cap funds\",\n",
    "    \"equity\", \"equities\", \"bonds\", \"futures\", \"options\", \"ipo\", \"ncds\", \"qip\",\n",
    "    \"gift\", \"experts\", \"investors\", \"promoters\", \"analysts\", \"traders\",\n",
    "    \"farmer bodies\", \"indian millers\", \"fii\", \"fiis\", \"nifty\", \"sensex\", \"dow jones\"\n",
    "}\n",
    "\n",
    "KEYWORD_RULES = {\n",
    "    \"COMMODITY\": COMMODITY,\n",
    "    \"GPE\": GPE,\n",
    "    \"CURRENCY\": CURRENCY,\n",
    "    \"CONCEPT\": CONCEPT\n",
    "}\n",
    "\n",
    "# Heuristic function to identify people's names\n",
    "def is_likely_person(name: str) -> bool:\n",
    "    parts = name.strip().split()\n",
    "    if len(parts) != 2: return False\n",
    "    if parts[0].isupper() and parts[1].isupper(): return False\n",
    "    return parts[0].istitle() and parts[1].istitle()\n",
    "\n",
    "# Main function to determine the label for any given name\n",
    "def get_entity_label(name: str) -> str:\n",
    "    name_lower = name.lower().strip()\n",
    "    for label, keywords in KEYWORD_RULES.items():\n",
    "        if name_lower in keywords:\n",
    "            return label\n",
    "    if is_likely_person(name):\n",
    "        return \"PERSON\"\n",
    "    return \"COMPANY\" # Fallback label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3639688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 10687, Training: 8549, Dev: 2138\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "TRAIN_DATA = []\n",
    "\n",
    "for _, row in data1.iterrows():\n",
    "    title = row['Title']\n",
    "    decision_dict = eval(row['Decisions'])\n",
    "    \n",
    "    entities_to_find = {name: get_entity_label(name) for name in decision_dict.keys()}\n",
    "    \n",
    "    entities_for_this_title = []\n",
    "    with nlp.select_pipes(disable=\"ner\"):\n",
    "        doc = nlp(title)\n",
    "\n",
    "    for name, label in entities_to_find.items():\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        # Using .strip() and LOWER for robust matching\n",
    "        pattern = [{\"LOWER\": token.lower_} for token in nlp(name.strip())]\n",
    "        matcher.add(\"ENTITY_PATTERN\", [pattern])\n",
    "        matches = matcher(doc)\n",
    "        \n",
    "        for match_id, start_token, end_token in matches:\n",
    "            span = doc[start_token:end_token]\n",
    "            entity = (span.start_char, span.end_char, label)\n",
    "            entities_for_this_title.append(entity)\n",
    "\n",
    "    if entities_for_this_title:\n",
    "        spans = [doc.char_span(s, e, label=l) for s, e, l in set(entities_for_this_title) if doc.char_span(s, e, label=l) is not None]\n",
    "        filtered_spans = filter_spans(spans)\n",
    "        final_entities = [(span.start_char, span.end_char, span.label_) for span in filtered_spans]\n",
    "        TRAIN_DATA.append((title, {\"entities\": final_entities}))\n",
    "train_data, dev_data = train_test_split(TRAIN_DATA, test_size=0.2, random_state=42)\n",
    "\n",
    "def create_spacy_files(data, output_path):\n",
    "    db = DocBin()\n",
    "    for text, annot in data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        doc.ents = [doc.char_span(s, e, label=l, alignment_mode=\"contract\") for s, e, l in annot[\"entities\"]]\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)\n",
    "\n",
    "\n",
    "create_spacy_files(train_data, \"./Data/train.spacy\")\n",
    "create_spacy_files(dev_data, \"./Data/dev.spacy\")\n",
    "print(f\"Total examples: {len(TRAIN_DATA)}, Training: {len(train_data)}, Dev: {len(dev_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610e0154",
   "metadata": {},
   "source": [
    "'python -m spacy train config_trf.cfg --output ./output_trf --gpu-id 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f26c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 sentences with prediction errors out of 2138.\n",
      "\n",
      "--- Reviewing 5 Random Mistakes ---\n",
      "\n",
      "TEXT: Federal Bank and Karnataka Bank safe bets in PSU banks: Mehraboon Irani\n",
      "TRUE: {(17, 31, 'PERSON'), (0, 12, 'PERSON')}\n",
      "PREDICTED: {(45, 54, 'COMPANY'), (17, 31, 'PERSON'), (0, 12, 'PERSON')}\n",
      "\n",
      "TEXT: Won leads Asia FX slide as volatile China stocks, Greece hit sentiment\n",
      "TRUE: {(0, 3, 'COMPANY'), (10, 17, 'COMPANY')}\n",
      "PREDICTED: {(0, 3, 'CURRENCY'), (10, 17, 'COMPANY')}\n",
      "\n",
      "TEXT: With auto sales gaining pace, brokers say auto ancillaries can give over 20% returns\n",
      "TRUE: {(42, 58, 'COMPANY')}\n",
      "PREDICTED: {(5, 15, 'COMPANY'), (42, 58, 'COMPANY')}\n",
      "\n",
      "TEXT: Chinese corporate bond market calm despite default by Chaori Solar\n",
      "TRUE: {(54, 66, 'PERSON')}\n",
      "PREDICTED: {(0, 29, 'COMPANY'), (54, 66, 'PERSON')}\n",
      "\n",
      "TEXT: Euro/USD looking at support between $1.3815-30\n",
      "TRUE: {(0, 8, 'COMPANY')}\n",
      "PREDICTED: {(0, 4, 'CURRENCY')}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "model_path = \"./output_trf/model-best\"\n",
    "nlp_trained = spacy.load(model_path)\n",
    "\n",
    "dev_file = \"./Data/dev.spacy\"\n",
    "doc_bin = DocBin().from_disk(dev_file)\n",
    "validation_data = []\n",
    "for doc in doc_bin.get_docs(nlp.vocab):\n",
    "    entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "    validation_data.append((doc.text, {\"entities\": entities}))\n",
    "\n",
    "mistakes = []\n",
    "for text, annotations in validation_data:\n",
    "    doc_predicted = nlp_trained(text)\n",
    "    true_entities = set(annotations['entities'])\n",
    "    predicted_entities = set((ent.start_char, ent.end_char, ent.label_) for ent in doc_predicted.ents)\n",
    "    \n",
    "    if true_entities != predicted_entities:\n",
    "        mistakes.append({\n",
    "            \"text\": text,\n",
    "            \"true_entities\": true_entities,\n",
    "            \"predicted_entities\": predicted_entities\n",
    "        })\n",
    "\n",
    "print(f\"Found {len(mistakes)} sentences with prediction errors out of {len(validation_data)}.\")\n",
    "\n",
    "print(\"\\n--- Reviewing 5 Random Mistakes ---\")\n",
    "if mistakes:\n",
    "    for item in random.sample(mistakes, min(5, len(mistakes))):\n",
    "        print(\"\\nTEXT:\", item['text'])\n",
    "        print(f\"TRUE: {item['true_entities']}\")\n",
    "        print(f\"PREDICTED: {item['predicted_entities']}\")\n",
    "else:\n",
    "    print(\"No mistakes found on the dev set!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
