name: Scrape News and Trigger Analysis

on:
  # Run the job every hour
  schedule:
    - cron: '0 * * * *'
  
  # Allows you to run this workflow manually from the Actions tab on GitHub
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Install Playwright browser and dependencies
        run: playwright install --with-deps chromium

      - name: Configure Kaggle API
        run: |
          # Create the .kaggle directory
          mkdir -p ~/.kaggle
          # Write the API credentials from GitHub Secrets into the kaggle.json file
          echo '${{ secrets.KAGGLE_API_CREDENTIALS }}' > ~/.kaggle/kaggle.json
          # Set the required file permissions for the kaggle.json file
          chmod 600 ~/.kaggle/kaggle.json

      - name: Run the Scraper and Trigger Analysis
        run: python scraper.py
        env:
          # This secret is used by scraper.py to connect to your Render database
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          
      - name: Check database entries
        if: always() # This step runs even if the previous step fails, for debugging.
        run: python check_db.py
        env:
          # This secret is also used by check_db.py
          DATABASE_URL: ${{ secrets.DATABASE_URL }}